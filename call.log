
KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94927e0790>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94927e0790>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949230b1d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949230b1d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492321d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492321d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923236d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923236d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492339110>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492339110>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949233ac10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949233ac10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9498104210>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9498104210>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949234de90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949234de90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949234eb90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949234eb90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923650d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923650d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492366a90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492366a90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923200d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923200d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492381e50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492381e50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492383810>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492383810>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949239d150>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949239d150>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949239ead0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949239ead0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94982e8210>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94982e8210>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923a9e90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923a9e90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923ab790>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923ab790>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923c5210>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923c5210>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923c6a50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923c6a50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923c7450>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923c7450>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923d9d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923d9d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923db710>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923db710>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923f4d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923f4d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923f69d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923f69d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923f7610>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923f7610>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492205dd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492205dd0>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94927e0790>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949230b1d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492321d10>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923236d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492339110>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949233ac10>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9498104210>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949234de90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949234eb90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923650d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492366a90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923200d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492381e50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492383810>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949239d150>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949239ead0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94982e8210>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923a9e90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923ab790>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923c5210>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923c6a50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923c7450>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923d9d10>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923db710>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923f4d10>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923f69d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923f7610>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492205dd0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94927e0790>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94927e0790>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949230b1d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949230b1d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492321d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492321d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923236d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923236d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492339110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492339110>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949233ac10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949233ac10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9498104210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9498104210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949234de90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949234de90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949234eb90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949234eb90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923650d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923650d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492366a90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492366a90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923200d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923200d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492381e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492381e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492383810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492383810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949239d150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949239d150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949239ead0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949239ead0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94982e8210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94982e8210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923a9e90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923a9e90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923ab790>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923ab790>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923c5210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923c5210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923c6a50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923c6a50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923c7450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923c7450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923d9d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923d9d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923db710>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923db710>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923f4d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923f4d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923f69d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923f69d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923f7610>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923f7610>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492205dd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492205dd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94927e0790>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94927e0790>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949230b1d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949230b1d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492321d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492321d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923236d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923236d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492339110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492339110>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949233ac10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949233ac10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9498104210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9498104210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949234de90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949234de90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949234eb90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949234eb90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923650d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923650d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492366a90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492366a90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923200d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923200d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492381e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492381e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492383810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492383810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949239d150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949239d150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949239ead0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b949239ead0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94982e8210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94982e8210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923a9e90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923a9e90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923ab790>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923ab790>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923c5210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923c5210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923c6a50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923c6a50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923c7450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923c7450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923d9d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923d9d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923db710>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923db710>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923f4d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923f4d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923f69d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923f69d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923f7610>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b94923f7610>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492205dd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b9492205dd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca734b2b0d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca734b2b0d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e917190>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e917190>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e917ed0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e917ed0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e97dad0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e97dad0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e97f6d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e97f6d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e9e5950>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e9e5950>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e9813d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e9813d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e9822d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e9822d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e982c90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e982c90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e9d5610>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e9d5610>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e9d7a10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e9d7a10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e9a5690>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e9a5690>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e9a6cd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e9a6cd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e9a7c10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e9a7c10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e98de50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e98de50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e98edd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e98edd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e968cd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e968cd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e968890>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e968890>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e96b9d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e96b9d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e951350>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e951350>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e953750>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e953750>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e92d0d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca71e92d0d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563c85ae250>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563c85ae250>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2942b90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2942b90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29438d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29438d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2afa850>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2afa850>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b6af8990>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b6af8990>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ea650>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ea650>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29c1cd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29c1cd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29c3910>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29c3910>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e4c50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e4c50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e6b90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e6b90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e7790>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e7790>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29a90d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29a90d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ab810>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ab810>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2990490>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2990490>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2991d90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2991d90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2993690>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2993690>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2971990>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2971990>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29736d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29736d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2954350>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2954350>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29569d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29569d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29575d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29575d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29358d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29358d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2936d50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2936d50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ecc50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ecc50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ee910>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ee910>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ef5d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ef5d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2500d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2500d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2502750>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2502750>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563c85ae250>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2942b90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29438d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2afa850>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b6af8990>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ea650>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29c1cd0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29c3910>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e4c50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e6b90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e7790>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29a90d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ab810>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2990490>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2991d90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2993690>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2971990>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29736d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2954350>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29569d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29575d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29358d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2936d50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ecc50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ee910>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ef5d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2500d10>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2502750>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563c85ae250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563c85ae250>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2942b90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2942b90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29438d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29438d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2afa850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2afa850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b6af8990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b6af8990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ea650>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ea650>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29c1cd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29c1cd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29c3910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29c3910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e4c50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e4c50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e6b90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e6b90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e7790>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e7790>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29a90d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29a90d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ab810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ab810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2990490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2990490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2991d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2991d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2993690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2993690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2971990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2971990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29736d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29736d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2954350>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2954350>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29569d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29569d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29575d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29575d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29358d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29358d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2936d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2936d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ecc50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ecc50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ee910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ee910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ef5d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ef5d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2500d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2500d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2502750>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2502750>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563c85ae250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563c85ae250>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2942b90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2942b90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29438d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29438d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2afa850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2afa850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b6af8990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b6af8990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ea650>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ea650>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29c1cd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29c1cd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29c3910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29c3910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e4c50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e4c50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e6b90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e6b90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e7790>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e7790>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29a90d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29a90d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ab810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ab810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2990490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2990490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2991d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2991d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2993690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2993690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2971990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2971990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29736d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29736d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2954350>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2954350>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29569d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29569d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29575d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29575d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29358d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29358d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2936d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2936d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ecc50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ecc50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ee910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ee910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ef5d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ef5d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2500d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2500d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2502750>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2502750>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563c85ae250>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2942b90>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29438d0>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2afa850>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b6af8990>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ea650>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29c1cd0>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29c3910>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e4c50>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e6b90>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e7790>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29a90d0>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ab810>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2990490>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2991d90>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2993690>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2971990>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29736d0>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2954350>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29569d0>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29575d0>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29358d0>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2936d50>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ecc50>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ee910>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ef5d0>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2500d10>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2502750>', 'Tensor(shape=torch.Size([30, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([30, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563c85ae250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563c85ae250>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2942b90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2942b90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29438d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29438d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2afa850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2afa850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b6af8990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b6af8990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ea650>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ea650>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29c1cd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29c1cd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29c3910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29c3910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e4c50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e4c50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e6b90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e6b90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e7790>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29e7790>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29a90d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29a90d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ab810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ab810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2990490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2990490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2991d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2991d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2993690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2993690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2971990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2971990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29736d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29736d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2954350>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2954350>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29569d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29569d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29575d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29575d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29358d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29358d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2936d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2936d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ecc50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ecc50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ee910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ee910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ef5d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b29ef5d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2500d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2500d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2502750>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7563b2502750>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b248fdd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b248fdd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb06210>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb06210>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb07d90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb07d90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ecd72d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ecd72d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb941d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb941d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb96390>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb96390>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe6290>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe6290>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe7b90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe7b90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebccd10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebccd10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebce1d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebce1d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebcfe90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebcfe90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebb93d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebb93d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebbb650>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebbb650>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7cd10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7cd10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7e950>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7e950>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b0600510>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b0600510>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59c90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59c90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59310>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59310>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb48550>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb48550>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb4a010>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb4a010>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b06004d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b06004d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7011d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7011d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e703850>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e703850>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71c890>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71c890>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71eb10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71eb10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71f410>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71f410>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7291d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7291d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e72aa10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e72aa10>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b248fdd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb06210>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb07d90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ecd72d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb941d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb96390>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe6290>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe7b90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebccd10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebce1d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebcfe90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebb93d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebbb650>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7cd10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7e950>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b0600510>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59c90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59310>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb48550>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb4a010>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b06004d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7011d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e703850>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71c890>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71eb10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71f410>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7291d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e72aa10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b248fdd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b248fdd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb06210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb06210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb07d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb07d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ecd72d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ecd72d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb941d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb941d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb96390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb96390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe6290>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe6290>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe7b90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe7b90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebccd10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebccd10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebce1d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebce1d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebcfe90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebcfe90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebb93d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebb93d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebbb650>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebbb650>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7cd10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7cd10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7e950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7e950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b0600510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b0600510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59c90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59c90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59310>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59310>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb48550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb48550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb4a010>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb4a010>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b06004d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b06004d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7011d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7011d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e703850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e703850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71c890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71c890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71eb10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71eb10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71f410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71f410>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7291d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7291d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e72aa10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e72aa10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b248fdd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b248fdd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb06210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb06210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb07d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb07d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ecd72d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ecd72d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb941d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb941d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb96390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb96390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe6290>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe6290>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe7b90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe7b90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebccd10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebccd10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebce1d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebce1d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebcfe90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebcfe90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebb93d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebb93d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebbb650>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebbb650>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7cd10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7cd10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7e950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7e950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b0600510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b0600510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59c90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59c90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59310>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59310>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb48550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb48550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb4a010>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb4a010>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b06004d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b06004d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7011d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7011d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e703850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e703850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71c890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71c890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71eb10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71eb10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71f410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71f410>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7291d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7291d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e72aa10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e72aa10>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b248fdd0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb06210>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb07d90>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ecd72d0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb941d0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb96390>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe6290>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe7b90>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebccd10>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebce1d0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebcfe90>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebb93d0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebbb650>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7cd10>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7e950>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b0600510>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59c90>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59310>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb48550>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb4a010>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b06004d0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7011d0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e703850>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71c890>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71eb10>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71f410>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7291d0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e72aa10>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b248fdd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b248fdd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb06210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb06210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb07d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb07d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ecd72d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ecd72d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb941d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb941d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb96390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb96390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe6290>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe6290>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe7b90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe7b90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebccd10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebccd10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebce1d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebce1d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebcfe90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebcfe90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebb93d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebb93d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebbb650>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebbb650>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7cd10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7cd10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7e950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7e950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b0600510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b0600510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59c90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59c90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59310>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59310>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb48550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb48550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb4a010>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb4a010>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b06004d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b06004d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7011d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7011d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e703850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e703850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71c890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71c890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71eb10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71eb10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71f410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71f410>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7291d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7291d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e72aa10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e72aa10>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b248fdd0>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb06210>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb07d90>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ecd72d0>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb941d0>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb96390>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe6290>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe7b90>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebccd10>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebce1d0>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebcfe90>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebb93d0>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebbb650>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7cd10>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7e950>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b0600510>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59c90>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59310>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb48550>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb4a010>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b06004d0>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7011d0>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e703850>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71c890>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71eb10>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71f410>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7291d0>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e72aa10>', 'Tensor(shape=torch.Size([28, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([28, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b248fdd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b248fdd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb06210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb06210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb07d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb07d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ecd72d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ecd72d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb941d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb941d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb96390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb96390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe6290>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe6290>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe7b90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebe7b90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebccd10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebccd10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebce1d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebce1d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebcfe90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebcfe90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebb93d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebb93d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebbb650>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939ebbb650>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7cd10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7cd10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7e950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb7e950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b0600510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b0600510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59c90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59c90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59310>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb59310>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb48550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb48550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb4a010>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939eb4a010>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b06004d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7493b06004d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7011d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7011d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e703850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e703850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71c890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71c890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71eb10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71eb10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71f410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e71f410>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7291d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e7291d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e72aa10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x74939e72aa10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0e1e2c10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0e1e2c10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd0fe10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd0fe10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd24a90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd24a90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd27110>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd27110>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd27b10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd27b10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd42410>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd42410>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd43d90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd43d90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd54a90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd54a90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd571d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd571d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd57b90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd57b90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd6e590>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd6e590>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd6fdd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd6fdd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd84c50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd84c50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd871d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd871d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd87e90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd87e90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dda2510>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dda2510>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dda3ed0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dda3ed0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddb9990>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddb9990>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddbb350>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddbb350>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddbbd10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddbbd10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddca590>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddca590>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddcb490>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddcb490>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dde1a10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dde1a10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dde3410>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dde3410>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dde3d50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dde3d50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddfa750>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddfa750>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddfbfd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddfbfd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dc01a10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dc01a10>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0e1e2c10>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd0fe10>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd24a90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd27110>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd27b10>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd42410>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd43d90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd54a90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd571d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd57b90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd6e590>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd6fdd0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd84c50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd871d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd87e90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dda2510>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dda3ed0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddb9990>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddbb350>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddbbd10>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddca590>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddcb490>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dde1a10>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dde3410>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dde3d50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddfa750>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddfbfd0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dc01a10>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0e1e2c10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0e1e2c10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd0fe10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd0fe10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd24a90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd24a90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd27110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd27110>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd27b10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd27b10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd42410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd42410>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd43d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd43d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd54a90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd54a90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd571d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd571d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd57b90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd57b90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd6e590>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd6e590>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd6fdd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd6fdd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd84c50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd84c50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd871d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd871d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd87e90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd87e90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dda2510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dda2510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dda3ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dda3ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddb9990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddb9990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddbb350>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddbb350>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddbbd10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddbbd10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddca590>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddca590>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddcb490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddcb490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dde1a10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dde1a10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dde3410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dde3410>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dde3d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dde3d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddfa750>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddfa750>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddfbfd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddfbfd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dc01a10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dc01a10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0e1e2c10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0e1e2c10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd0fe10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd0fe10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd24a90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd24a90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd27110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd27110>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd27b10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd27b10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd42410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd42410>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd43d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd43d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd54a90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd54a90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd571d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd571d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd57b90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd57b90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd6e590>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd6e590>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd6fdd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd6fdd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd84c50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd84c50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd871d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd871d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd87e90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dd87e90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dda2510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dda2510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dda3ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dda3ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddb9990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddb9990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddbb350>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddbb350>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddbbd10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddbbd10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddca590>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddca590>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddcb490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddcb490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dde1a10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dde1a10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dde3410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dde3410>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dde3d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dde3d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddfa750>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddfa750>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddfbfd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0ddfbfd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dc01a10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78ef0dc01a10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b883f50d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b883f50d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b828fbed0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b828fbed0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82715850>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82715850>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82717150>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82717150>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82717950>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82717950>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82732590>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82732590>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82733e10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82733e10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827458d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827458d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82747250>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82747250>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82747e50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82747e50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8275e4d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8275e4d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8275fdd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8275fdd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82779790>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82779790>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8277b150>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8277b150>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8277b990>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8277b990>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82792250>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82792250>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82793fd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82793fd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a4d90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a4d90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a7250>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a7250>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a7d50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a7d50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827ba450>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827ba450>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827bbe90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827bbe90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827c9810>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827c9810>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827cb290>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827cb290>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827cbd10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827cbd10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827ea690>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827ea690>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827eb3d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827eb3d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827fd250>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827fd250>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b883f50d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b828fbed0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82715850>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82717150>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82717950>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82732590>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82733e10>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827458d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82747250>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82747e50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8275e4d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8275fdd0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82779790>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8277b150>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8277b990>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82792250>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82793fd0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a4d90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a7250>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a7d50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827ba450>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827bbe90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827c9810>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827cb290>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827cbd10>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827ea690>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827eb3d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827fd250>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b883f50d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b883f50d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b828fbed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b828fbed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82715850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82715850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82717150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82717150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82717950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82717950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82732590>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82732590>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82733e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82733e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827458d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827458d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82747250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82747250>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82747e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82747e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8275e4d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8275e4d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8275fdd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8275fdd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82779790>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82779790>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8277b150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8277b150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8277b990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8277b990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82792250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82792250>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82793fd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82793fd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a4d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a4d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a7250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a7250>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a7d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a7d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827ba450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827ba450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827bbe90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827bbe90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827c9810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827c9810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827cb290>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827cb290>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827cbd10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827cbd10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827ea690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827ea690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827eb3d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827eb3d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827fd250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827fd250>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b883f50d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b883f50d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b828fbed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b828fbed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82715850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82715850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82717150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82717150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82717950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82717950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82732590>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82732590>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82733e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82733e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827458d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827458d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82747250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82747250>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82747e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82747e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8275e4d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8275e4d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8275fdd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8275fdd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82779790>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82779790>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8277b150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8277b150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8277b990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8277b990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82792250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82792250>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82793fd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82793fd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a4d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a4d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a7250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a7250>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a7d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a7d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827ba450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827ba450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827bbe90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827bbe90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827c9810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827c9810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827cb290>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827cb290>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827cbd10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827cbd10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827ea690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827ea690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827eb3d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827eb3d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827fd250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827fd250>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b883f50d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b828fbed0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82715850>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82717150>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82717950>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82732590>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82733e10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827458d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82747250>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82747e50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8275e4d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8275fdd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82779790>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8277b150>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8277b990>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82792250>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82793fd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a4d90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a7250>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a7d50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827ba450>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827bbe90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827c9810>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827cb290>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827cbd10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827ea690>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827eb3d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827fd250>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b883f50d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b883f50d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b828fbed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b828fbed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82715850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82715850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82717150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82717150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82717950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82717950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82732590>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82732590>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82733e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82733e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827458d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827458d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82747250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82747250>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82747e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82747e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8275e4d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8275e4d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8275fdd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8275fdd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82779790>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82779790>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8277b150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8277b150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8277b990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b8277b990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82792250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82792250>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82793fd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b82793fd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a4d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a4d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a7250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a7250>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a7d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827a7d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827ba450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827ba450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827bbe90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827bbe90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827c9810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827c9810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827cb290>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827cb290>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827cbd10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827cbd10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827ea690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827ea690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827eb3d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827eb3d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827fd250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x704b827fd250>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75bf22831650>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75bf22831650>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75bf0e91aed0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75bf0e91aed0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75bf0e91b6d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75bf0e91b6d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75bf0e980d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75bf0e980d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75bf0e981310>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75bf0e981310>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f25420df610>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f25420df610>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f2541f16d50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f2541f16d50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f2541f17b10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f2541f17b10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f2541f85c50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f2541f85c50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f2541f868d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f2541f868d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f2541fef490>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f2541fef490>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7827b1150d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7827b1150d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f30f550>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f30f550>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f325d90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f325d90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3277d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3277d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f339190>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f339190>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f33ac50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f33ac50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f33b8d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f33b8d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f355fd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f355fd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3579d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3579d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f369350>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f369350>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f36acd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f36acd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f36b950>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f36b950>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f386150>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f386150>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3879d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3879d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f39d450>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f39d450>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f39ee10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f39ee10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f39fa90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f39fa90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3ae1d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3ae1d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3aee90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3aee90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3c9490>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3c9490>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3ca110>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3ca110>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3cbc10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3cbc10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3dd450>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3dd450>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3dfa50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3dfa50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3f9510>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3f9510>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3fae90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3fae90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3fb6d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f3fb6d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f20e390>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x78279f20e390>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725163a20d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725163a20d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f09010>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f09010>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f0a990>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f0a990>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f0b2d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f0b2d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f1dd10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f1dd10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f1ecd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f1ecd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f3cf90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f3cf90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f3e950>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f3e950>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f3f250>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f3f250>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f4dd10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f4dd10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f4f5d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f4f5d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f6cfd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f6cfd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f6e990>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f6e990>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f6fc90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f6fc90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f81b90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f81b90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f83510>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f83510>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f94f90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f94f90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f96810>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f96810>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f97710>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161f97710>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161fadc10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161fadc10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161faf510>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161faf510>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161fbcf90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161fbcf90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161fbe110>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161fbe110>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161fbf4d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161fbf4d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161fd9c90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161fd9c90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161fdb5d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161fdb5d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161ff4c50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161ff4c50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161ff6950>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x725161ff6950>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe93b10d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe93b10d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d13a90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d13a90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d2e150>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d2e150>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d2fa90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d2fa90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d40c50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d40c50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d42a50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d42a50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d43710>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d43710>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d5e150>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d5e150>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d5fa90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d5fa90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d70750>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d70750>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d72cd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d72cd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d73950>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d73950>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d8e150>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d8e150>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d8f950>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91d8f950>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91da4c50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91da4c50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91da6d50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91da6d50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91da7950>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91da7950>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91db6150>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91db6150>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91db7b10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91db7b10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91dd14d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91dd14d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91dd2f10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91dd2f10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91dd3850>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91dd3850>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91de5550>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91de5550>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91de7bd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91de7bd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91c01490>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91c01490>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91c02fd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91c02fd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91de4510>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91de4510>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91c16190>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bbe91c16190>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1c200d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1c200d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16701d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16701d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16703610>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16703610>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb168ed750>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb168ed750>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb168ef490>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb168ef490>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1630b8d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1630b8d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167e8550>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167e8550>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167eabd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167eabd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb168ef810>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb168ef810>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167d91d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167d91d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167daf10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167daf10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167bcd10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167bcd10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167be6d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167be6d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167be5d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167be5d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167a5910>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167a5910>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167a72d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167a72d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16780b90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16780b90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16781ad0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16781ad0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167834d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167834d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16768d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16768d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1676aad0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1676aad0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1676bf50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1676bf50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16719a90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16719a90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1671b550>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1671b550>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16315850>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16315850>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16317210>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16317210>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16317ed0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16317ed0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1632e510>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1632e510>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1c200d10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16701d10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16703610>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb168ed750>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb168ef490>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1630b8d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167e8550>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167eabd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb168ef810>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167d91d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167daf10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167bcd10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167be6d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167be5d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167a5910>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167a72d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16780b90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16781ad0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167834d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16768d10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1676aad0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1676bf50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16719a90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1671b550>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16315850>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16317210>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16317ed0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1632e510>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1c200d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1c200d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16701d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16701d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16703610>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16703610>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb168ed750>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb168ed750>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb168ef490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb168ef490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1630b8d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1630b8d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167e8550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167e8550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167eabd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167eabd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb168ef810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb168ef810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167d91d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167d91d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167daf10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167daf10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167bcd10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167bcd10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167be6d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167be6d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167be5d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167be5d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167a5910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167a5910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167a72d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167a72d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16780b90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16780b90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16781ad0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16781ad0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167834d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167834d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16768d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16768d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1676aad0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1676aad0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1676bf50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1676bf50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16719a90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16719a90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1671b550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1671b550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16315850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16315850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16317210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16317210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16317ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16317ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1632e510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1632e510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1c200d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1c200d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16701d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16701d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16703610>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16703610>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb168ed750>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb168ed750>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb168ef490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb168ef490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1630b8d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1630b8d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167e8550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167e8550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167eabd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167eabd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb168ef810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb168ef810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167d91d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167d91d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167daf10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167daf10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167bcd10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167bcd10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167be6d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167be6d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167be5d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167be5d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167a5910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167a5910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167a72d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167a72d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16780b90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16780b90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16781ad0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16781ad0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167834d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb167834d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16768d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16768d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1676aad0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1676aad0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1676bf50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1676bf50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16719a90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16719a90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1671b550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1671b550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16315850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16315850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16317210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16317210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16317ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb16317ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1632e510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x71cb1632e510>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca110952c10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ca110952c10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9f11565950>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9f11565950>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3099d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3099d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe30be50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe30be50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe375210>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe375210>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe375bd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe375bd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3e12d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3e12d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3e3f90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3e3f90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe37d810>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe37d810>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe37ed50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe37ed50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3c0ad0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3c0ad0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3c2410>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3c2410>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3c3d90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3c3d90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3a9690>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3a9690>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3aad50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3aad50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe390690>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe390690>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe392210>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe392210>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe393950>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe393950>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe365110>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe365110>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe366d50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe366d50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe34c710>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe34c710>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe34e050>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe34e050>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe34fc50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe34fc50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe329390>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe329390>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe32ae50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe32ae50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3f0650>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3f0650>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3f1f10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3f1f10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3f3910>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3f3910>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efdf053d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efdf053d0>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9f11565950>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3099d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe30be50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe375210>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe375bd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3e12d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3e3f90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe37d810>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe37ed50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3c0ad0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3c2410>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3c3d90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3a9690>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3aad50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe390690>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe392210>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe393950>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe365110>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe366d50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe34c710>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe34e050>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe34fc50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe329390>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe32ae50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3f0650>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3f1f10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3f3910>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efdf053d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9f11565950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9f11565950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3099d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3099d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe30be50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe30be50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe375210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe375210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe375bd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe375bd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3e12d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3e12d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3e3f90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3e3f90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe37d810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe37d810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe37ed50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe37ed50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3c0ad0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3c0ad0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3c2410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3c2410>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3c3d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3c3d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3a9690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3a9690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3aad50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3aad50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe390690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe390690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe392210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe392210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe393950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe393950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe365110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe365110>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe366d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe366d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe34c710>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe34c710>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe34e050>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe34e050>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe34fc50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe34fc50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe329390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe329390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe32ae50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe32ae50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3f0650>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3f0650>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3f1f10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3f1f10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3f3910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3f3910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efdf053d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efdf053d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9f11565950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9f11565950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3099d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3099d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe30be50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe30be50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe375210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe375210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe375bd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe375bd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3e12d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3e12d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3e3f90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3e3f90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe37d810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe37d810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe37ed50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe37ed50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3c0ad0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3c0ad0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3c2410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3c2410>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3c3d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3c3d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3a9690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3a9690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3aad50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3aad50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe390690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe390690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe392210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe392210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe393950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe393950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe365110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe365110>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe366d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe366d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe34c710>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe34c710>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe34e050>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe34e050>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe34fc50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe34fc50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe329390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe329390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe32ae50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe32ae50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3f0650>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3f0650>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3f1f10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3f1f10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3f3910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efe3f3910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efdf053d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7f9efdf053d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb3c89210>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb3c89210>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb150e110>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb150e110>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb150fc50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb150fc50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb157cc90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb157cc90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb157e8d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb157e8d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15e9ad0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15e9ad0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1580950>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1580950>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1582550>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1582550>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1583810>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1583810>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15dd3d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15dd3d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15deb10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15deb10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15ac910>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15ac910>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15ae0d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15ae0d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15aec90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15aec90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1591790>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1591790>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1592e10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1592e10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1569210>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1569210>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb156a050>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb156a050>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb156b610>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb156b610>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1551410>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1551410>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1552f50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1552f50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1530710>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1530710>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1531ed0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1531ed0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1533550>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1533550>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15f9110>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15f9110>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15faa50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15faa50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb110d010>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb110d010>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb110dc90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb110dc90>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb3c89210>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb150e110>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb150fc50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb157cc90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb157e8d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15e9ad0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1580950>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1582550>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1583810>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15dd3d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15deb10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15ac910>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15ae0d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15aec90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1591790>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1592e10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1569210>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb156a050>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb156b610>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1551410>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1552f50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1530710>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1531ed0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1533550>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15f9110>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15faa50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb110d010>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb110dc90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb3c89210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb3c89210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb150e110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb150e110>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb150fc50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb150fc50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb157cc90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb157cc90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb157e8d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb157e8d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15e9ad0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15e9ad0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1580950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1580950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1582550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1582550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1583810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1583810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15dd3d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15dd3d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15deb10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15deb10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15ac910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15ac910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15ae0d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15ae0d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15aec90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15aec90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1591790>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1591790>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1592e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1592e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1569210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1569210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb156a050>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb156a050>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb156b610>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb156b610>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1551410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1551410>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1552f50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1552f50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1530710>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1530710>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1531ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1531ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1533550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1533550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15f9110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15f9110>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15faa50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15faa50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb110d010>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb110d010>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb110dc90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb110dc90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb3c89210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb3c89210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb150e110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb150e110>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb150fc50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb150fc50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb157cc90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb157cc90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb157e8d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb157e8d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15e9ad0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15e9ad0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1580950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1580950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1582550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1582550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1583810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1583810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15dd3d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15dd3d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15deb10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15deb10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15ac910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15ac910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15ae0d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15ae0d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15aec90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15aec90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1591790>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1591790>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1592e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1592e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1569210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1569210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb156a050>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb156a050>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb156b610>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb156b610>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1551410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1551410>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1552f50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1552f50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1530710>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1530710>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1531ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1531ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1533550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb1533550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15f9110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15f9110>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15faa50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb15faa50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb110d010>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb110d010>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb110dc90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x701bb110dc90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d6bf8d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d6bf8d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2bfe5d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2bfe5d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27187d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27187d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2719750>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2719750>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d271b390>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d271b390>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d272d4d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d272d4d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d272e2d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d272e2d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2744150>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2744150>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27462d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27462d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27475d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27475d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d275cc90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d275cc90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d275e590>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d275e590>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2778890>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2778890>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2779bd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2779bd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d277bc90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d277bc90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2790e50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2790e50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2792fd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2792fd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27a02d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27a02d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27a1d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27a1d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27a3790>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27a3790>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27b90d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27b90d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27ba990>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27ba990>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27d4090>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27d4090>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27d6450>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27d6450>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27d7dd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27d7dd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27e9750>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27e9750>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27eb150>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27eb150>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d1d04450>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d1d04450>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d6bf8d10>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2bfe5d0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27187d0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2719750>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d271b390>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d272d4d0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d272e2d0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2744150>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27462d0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27475d0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d275cc90>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d275e590>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2778890>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2779bd0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d277bc90>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2790e50>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2792fd0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27a02d0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27a1d10>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27a3790>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27b90d0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27ba990>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27d4090>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27d6450>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27d7dd0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27e9750>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27eb150>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d1d04450>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d6bf8d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d6bf8d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2bfe5d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2bfe5d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27187d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27187d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2719750>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2719750>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d271b390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d271b390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d272d4d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d272d4d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d272e2d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d272e2d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2744150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2744150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27462d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27462d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27475d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27475d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d275cc90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d275cc90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d275e590>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d275e590>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2778890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2778890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2779bd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2779bd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d277bc90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d277bc90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2790e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2790e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2792fd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2792fd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27a02d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27a02d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27a1d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27a1d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27a3790>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27a3790>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27b90d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27b90d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27ba990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27ba990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27d4090>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27d4090>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27d6450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27d6450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27d7dd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27d7dd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27e9750>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27e9750>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27eb150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27eb150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d1d04450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d1d04450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d6bf8d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d6bf8d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2bfe5d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2bfe5d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27187d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27187d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2719750>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2719750>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d271b390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d271b390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d272d4d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d272d4d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d272e2d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d272e2d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2744150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2744150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27462d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27462d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27475d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27475d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d275cc90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d275cc90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d275e590>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d275e590>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2778890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2778890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2779bd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2779bd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d277bc90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d277bc90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2790e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2790e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2792fd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d2792fd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27a02d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27a02d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27a1d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27a1d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27a3790>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27a3790>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27b90d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27b90d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27ba990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27ba990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27d4090>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27d4090>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27d6450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27d6450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27d7dd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27d7dd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27e9750>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27e9750>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27eb150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d27eb150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d1d04450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bf0d1d04450>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb254a95d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb254a95d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f309c10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f309c10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f30bd10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f30bd10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f374d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f374d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f376110>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f376110>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3e1b50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3e1b50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f37c210>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f37c210>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f37db90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f37db90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f37f790>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f37f790>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3e9190>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3e9190>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3ea490>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3ea490>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3a8110>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3a8110>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3a9c10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3a9c10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3ab0d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3ab0d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3910d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3910d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f392790>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f392790>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f364c50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f364c50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f365b10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f365b10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f366f90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f366f90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f34cd90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f34cd90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f34e310>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f34e310>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3280d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3280d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f329650>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f329650>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f32af90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f32af90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3ecc10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3ecc10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3ee690>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3ee690>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb212e8a90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb212e8a90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f201750>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f201750>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb254a95d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f309c10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f30bd10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f374d10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f376110>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3e1b50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f37c210>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f37db90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f37f790>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3e9190>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3ea490>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3a8110>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3a9c10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3ab0d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3910d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f392790>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f364c50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f365b10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f366f90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f34cd90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f34e310>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3280d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f329650>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f32af90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3ecc10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f3ee690>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb212e8a90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb0f201750>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ebb254a95d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc56748d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc56748d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529070d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529070d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52918bd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52918bd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc5291a390>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc5291a390>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc5291bdd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc5291bdd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52931410>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52931410>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52932dd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52932dd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52944a90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52944a90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52946510>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52946510>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52946f50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52946f50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc5295e010>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc5295e010>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc5295ee10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc5295ee10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52978a90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52978a90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc5297a810>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc5297a810>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52994d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52994d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52995b50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52995b50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52997b50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52997b50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529a0d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529a0d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529a2910>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529a2910>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529bcc50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529bcc50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529bdc50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529bdc50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529bf7d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529bf7d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529cd750>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529cd750>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529ce8d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529ce8d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529ecd10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529ecd10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529ed7d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529ed7d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529efd50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529efd50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52801050>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52801050>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc56748d10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529070d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52918bd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc5291a390>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc5291bdd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52931410>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52932dd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52944a90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52946510>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52946f50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc5295e010>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc5295ee10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52978a90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc5297a810>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52994d10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52995b50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52997b50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529a0d10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529a2910>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529bcc50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529bdc50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529bf7d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529cd750>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529ce8d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529ecd10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529ed7d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc529efd50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc52801050>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x77fc56748d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce432f78d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce432f78d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce41306050>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce41306050>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce41307d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce41307d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce4136cc10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce4136cc10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce4136e610>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce4136e610>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce417fded0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce417fded0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413702d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413702d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce41372090>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce41372090>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce41373610>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce41373610>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413d5110>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413d5110>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413d69d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413d69d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413a4390>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413a4390>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413a5ad0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413a5ad0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413a7b10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413a7b10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce4138ce10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce4138ce10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce4138ebd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce4138ebd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413607d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413607d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce41361f10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce41361f10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce41363b10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce41363b10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413491d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413491d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce4134ab50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce4134ab50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce41328090>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce41328090>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce41329a50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce41329a50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce4132ba90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce4132ba90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413e9350>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413e9350>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413ea9d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413ea9d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413fcf50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413fcf50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413fdcd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413fdcd0>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce432f78d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce41306050>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce41307d10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce4136cc10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce4136e610>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce417fded0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413702d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce41372090>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce41373610>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413d5110>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413d69d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413a4390>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413a5ad0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413a7b10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce4138ce10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce4138ebd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413607d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce41361f10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce41363b10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413491d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce4134ab50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce41328090>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce41329a50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce4132ba90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413e9350>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413ea9d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413fcf50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce413fdcd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7bce432f78d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea78fd0d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea78fd0d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3919850>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3919850>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea391bb10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea391bb10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3984110>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3984110>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3985890>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3985890>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ecf10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ecf10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39efe90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39efe90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398d450>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398d450>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398ec10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398ec10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c45d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c45d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c6310>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c6310>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c7d90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c7d90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ad610>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ad610>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39aebd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39aebd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3994550>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3994550>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3995f50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3995f50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3997b10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3997b10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396d450>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396d450>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396f050>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396f050>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39548d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39548d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39563d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39563d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3957790>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3957790>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3930b50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3930b50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3932cd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3932cd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f00490>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f00490>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f02250>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f02250>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f03a10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f03a10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f14fd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f14fd0>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea78fd0d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3919850>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea391bb10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3984110>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3985890>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ecf10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39efe90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398d450>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398ec10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c45d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c6310>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c7d90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ad610>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39aebd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3994550>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3995f50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3997b10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396d450>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396f050>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39548d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39563d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3957790>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3930b50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3932cd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f00490>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f02250>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f03a10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f14fd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea78fd0d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea78fd0d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3919850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3919850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea391bb10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea391bb10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3984110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3984110>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3985890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3985890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ecf10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ecf10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39efe90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39efe90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398d450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398d450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398ec10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398ec10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c45d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c45d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c6310>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c6310>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c7d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c7d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ad610>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ad610>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39aebd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39aebd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3994550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3994550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3995f50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3995f50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3997b10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3997b10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396d450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396d450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396f050>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396f050>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39548d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39548d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39563d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39563d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3957790>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3957790>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3930b50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3930b50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3932cd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3932cd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f00490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f00490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f02250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f02250>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f03a10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f03a10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f14fd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f14fd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea78fd0d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea78fd0d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3919850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3919850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea391bb10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea391bb10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3984110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3984110>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3985890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3985890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ecf10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ecf10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39efe90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39efe90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398d450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398d450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398ec10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398ec10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c45d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c45d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c6310>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c6310>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c7d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c7d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ad610>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ad610>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39aebd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39aebd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3994550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3994550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3995f50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3995f50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3997b10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3997b10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396d450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396d450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396f050>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396f050>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39548d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39548d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39563d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39563d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3957790>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3957790>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3930b50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3930b50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3932cd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3932cd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f00490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f00490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f02250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f02250>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f03a10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f03a10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f14fd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f14fd0>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea78fd0d0>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3919850>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea391bb10>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3984110>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3985890>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ecf10>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39efe90>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398d450>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398ec10>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c45d0>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c6310>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c7d90>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ad610>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39aebd0>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3994550>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3995f50>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3997b10>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396d450>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396f050>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39548d0>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39563d0>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3957790>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3930b50>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3932cd0>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f00490>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f02250>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f03a10>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f14fd0>', 'Tensor(shape=torch.Size([23, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([23, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea78fd0d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea78fd0d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3919850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3919850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea391bb10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea391bb10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3984110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3984110>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3985890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3985890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ecf10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ecf10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39efe90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39efe90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398d450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398d450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398ec10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398ec10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c45d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c45d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c6310>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c6310>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c7d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c7d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ad610>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ad610>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39aebd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39aebd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3994550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3994550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3995f50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3995f50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3997b10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3997b10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396d450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396d450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396f050>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396f050>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39548d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39548d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39563d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39563d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3957790>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3957790>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3930b50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3930b50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3932cd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3932cd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f00490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f00490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f02250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f02250>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f03a10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f03a10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f14fd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f14fd0>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea78fd0d0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3919850>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea391bb10>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3984110>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3985890>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ecf10>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39efe90>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398d450>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398ec10>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c45d0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c6310>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c7d90>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ad610>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39aebd0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3994550>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3995f50>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3997b10>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396d450>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396f050>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39548d0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39563d0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3957790>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3930b50>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3932cd0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f00490>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f02250>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f03a10>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f14fd0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea78fd0d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea78fd0d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3919850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3919850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea391bb10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea391bb10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3984110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3984110>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3985890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3985890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ecf10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ecf10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39efe90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39efe90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398d450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398d450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398ec10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea398ec10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c45d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c45d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c6310>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c6310>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c7d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39c7d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ad610>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39ad610>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39aebd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39aebd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3994550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3994550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3995f50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3995f50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3997b10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3997b10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396d450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396d450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396f050>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea396f050>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39548d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39548d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39563d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea39563d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3957790>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3957790>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3930b50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3930b50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3932cd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea3932cd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f00490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f00490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f02250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f02250>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f03a10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f03a10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f14fd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x76fea2f14fd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d717053d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d717053d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db11b50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db11b50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db13dd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db13dd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db7c550>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db7c550>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db7dd90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db7dd90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbead90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbead90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db88210>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db88210>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db898d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db898d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db8ae50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db8ae50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbdcb10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbdcb10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbde610>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbde610>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbdff50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbdff50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbad590>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbad590>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbaf150>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbaf150>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db94950>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db94950>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db961d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db961d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db97950>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db97950>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db69310>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db69310>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db6ac50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db6ac50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db50650>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db50650>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db52350>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db52350>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db53b90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db53b90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db318d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db318d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db33050>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db33050>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbf4990>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbf4990>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbf6550>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbf6550>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbf7e50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbf7e50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5da0d390>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5da0d390>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d717053d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db11b50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db13dd0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db7c550>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db7dd90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbead90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db88210>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db898d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db8ae50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbdcb10>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbde610>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbdff50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbad590>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbaf150>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db94950>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db961d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db97950>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db69310>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db6ac50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db50650>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db52350>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db53b90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db318d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db33050>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbf4990>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbf6550>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbf7e50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5da0d390>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d717053d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d717053d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db11b50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db11b50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db13dd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db13dd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db7c550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db7c550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db7dd90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db7dd90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbead90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbead90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db88210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db88210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db898d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db898d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db8ae50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db8ae50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbdcb10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbdcb10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbde610>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbde610>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbdff50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbdff50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbad590>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbad590>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbaf150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbaf150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db94950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db94950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db961d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db961d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db97950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db97950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db69310>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db69310>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db6ac50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db6ac50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db50650>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db50650>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db52350>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db52350>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db53b90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db53b90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db318d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db318d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db33050>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db33050>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbf4990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbf4990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbf6550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbf6550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbf7e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbf7e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5da0d390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5da0d390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d717053d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d717053d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db11b50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db11b50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db13dd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db13dd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db7c550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db7c550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db7dd90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db7dd90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbead90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbead90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db88210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db88210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db898d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db898d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db8ae50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db8ae50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbdcb10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbdcb10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbde610>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbde610>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbdff50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbdff50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbad590>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbad590>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbaf150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbaf150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db94950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db94950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db961d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db961d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db97950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db97950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db69310>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db69310>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db6ac50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db6ac50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db50650>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db50650>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db52350>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db52350>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db53b90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db53b90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db318d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db318d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db33050>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5db33050>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbf4990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbf4990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbf6550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbf6550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbf7e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5dbf7e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5da0d390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x794d5da0d390>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b1c34196a90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b1c34196a90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b1c1e70fe90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b1c1e70fe90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b1c1e725610>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b1c1e725610>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b1c1e726d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b1c1e726d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b1c1e73cc50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b1c1e73cc50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b1c1e73e190>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b1c1e73e190>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336ebde90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336ebde90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336efa550>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336efa550>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336efbf90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336efbf90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d12090>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d12090>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d13a50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d13a50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d24890>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d24890>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d26550>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d26550>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d3c910>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d3c910>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d3db10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d3db10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d3f550>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d3f550>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d55690>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d55690>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d56490>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d56490>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d70290>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d70290>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d71cd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d71cd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d73d90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d73d90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d88dd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d88dd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d8a990>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d8a990>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d98310>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d98310>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d99dd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d99dd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d9bf50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d9bf50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336db1910>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336db1910>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336db3350>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336db3350>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336dc8e10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336dc8e10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336dca850>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336dca850>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336dcbc50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336dcbc50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336de1390>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336de1390>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336de2d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336de2d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336df8310>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336df8310>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336ebde90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336efa550>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336efbf90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d12090>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d13a50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d24890>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d26550>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d3c910>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d3db10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d3f550>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d55690>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d56490>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d70290>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d71cd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d73d90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d88dd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d8a990>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d98310>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d99dd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d9bf50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336db1910>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336db3350>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336dc8e10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336dca850>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336dcbc50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336de1390>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336de2d10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336df8310>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336ebde90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336ebde90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336efa550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336efa550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336efbf90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336efbf90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d12090>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d12090>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d13a50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d13a50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d24890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d24890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d26550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d26550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d3c910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d3c910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d3db10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d3db10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d3f550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d3f550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d55690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d55690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d56490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d56490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d70290>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d70290>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d71cd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d71cd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d73d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d73d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d88dd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d88dd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d8a990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d8a990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d98310>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d98310>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d99dd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d99dd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d9bf50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d9bf50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336db1910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336db1910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336db3350>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336db3350>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336dc8e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336dc8e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336dca850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336dca850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336dcbc50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336dcbc50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336de1390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336de1390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336de2d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336de2d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336df8310>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336df8310>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336ebde90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336ebde90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336efa550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336efa550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336efbf90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336efbf90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d12090>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d12090>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d13a50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d13a50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d24890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d24890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d26550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d26550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d3c910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d3c910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d3db10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d3db10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d3f550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d3f550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d55690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d55690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d56490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d56490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d70290>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d70290>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d71cd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d71cd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d73d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d73d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d88dd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d88dd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d8a990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d8a990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d98310>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d98310>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d99dd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d99dd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d9bf50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336d9bf50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336db1910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336db1910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336db3350>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336db3350>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336dc8e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336dc8e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336dca850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336dca850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336dcbc50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336dcbc50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336de1390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336de1390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336de2d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336de2d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336df8310>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7a9336df8310>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c3fccdd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c3fccdd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c050be90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c050be90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c051cc50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c051cc50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c051ea90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c051ea90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0534050>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0534050>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0536590>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0536590>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0537f10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0537f10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0549950>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0549950>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c054b350>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c054b350>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0560d50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0560d50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0562090>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0562090>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0563ad0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0563ad0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c057ced0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c057ced0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c057ead0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c057ead0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0594710>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0594710>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0595e10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0595e10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0597dd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0597dd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05a5490>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05a5490>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05a6d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05a6d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05c0e10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05c0e10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05c27d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05c27d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05c3550>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05c3550>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05d0ed0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05d0ed0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05d2850>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05d2850>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05f0490>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05f0490>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05f2010>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05f2010>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05f3ad0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05f3ad0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0405490>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0405490>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c3fccdd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c050be90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c051cc50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c051ea90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0534050>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0536590>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0537f10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0549950>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c054b350>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0560d50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0562090>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0563ad0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c057ced0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c057ead0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0594710>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0595e10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0597dd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05a5490>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05a6d10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05c0e10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05c27d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05c3550>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05d0ed0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05d2850>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05f0490>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05f2010>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05f3ad0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0405490>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c3fccdd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c3fccdd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c050be90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c050be90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c051cc50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c051cc50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c051ea90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c051ea90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0534050>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0534050>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0536590>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0536590>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0537f10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0537f10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0549950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0549950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c054b350>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c054b350>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0560d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0560d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0562090>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0562090>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0563ad0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0563ad0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c057ced0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c057ced0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c057ead0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c057ead0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0594710>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0594710>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0595e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0595e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0597dd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0597dd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05a5490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05a5490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05a6d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05a6d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05c0e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05c0e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05c27d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05c27d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05c3550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05c3550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05d0ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05d0ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05d2850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05d2850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05f0490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05f0490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05f2010>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05f2010>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05f3ad0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05f3ad0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0405490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0405490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c3fccdd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c3fccdd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c050be90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c050be90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c051cc50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c051cc50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c051ea90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c051ea90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0534050>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0534050>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0536590>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0536590>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0537f10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0537f10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0549950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0549950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c054b350>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c054b350>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0560d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0560d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0562090>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0562090>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0563ad0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0563ad0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c057ced0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c057ced0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c057ead0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c057ead0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0594710>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0594710>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0595e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0595e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0597dd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0597dd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05a5490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05a5490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05a6d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05a6d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05c0e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05c0e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05c27d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05c27d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05c3550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05c3550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05d0ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05d0ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05d2850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05d2850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05f0490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05f0490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05f2010>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05f2010>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05f3ad0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c05f3ad0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0405490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7c72c0405490>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9972c8d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9972c8d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9937fb0d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9937fb0d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99330d1d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99330d1d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99330e790>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99330e790>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993324a90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993324a90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993326450>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993326450>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993327d50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993327d50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993338d90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993338d90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99333a990>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99333a990>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993350310>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993350310>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993351e50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993351e50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993353dd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993353dd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99336d750>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99336d750>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99336e510>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99336e510>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993384190>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993384190>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993385d50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993385d50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993387510>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993387510>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993394fd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993394fd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993396910>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993396910>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933b0050>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933b0050>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933b2390>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933b2390>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933b3dd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933b3dd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933c17d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933c17d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933c27d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933c27d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933e0450>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933e0450>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933e1d90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933e1d90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933e3e50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933e3e50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933f58d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933f58d0>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9972c8d10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9937fb0d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99330d1d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99330e790>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993324a90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993326450>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993327d50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993338d90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99333a990>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993350310>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993351e50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993353dd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99336d750>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99336e510>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993384190>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993385d50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993387510>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993394fd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993396910>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933b0050>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933b2390>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933b3dd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933c17d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933c27d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933e0450>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933e1d90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933e3e50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933f58d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9972c8d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9972c8d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9937fb0d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9937fb0d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99330d1d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99330d1d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99330e790>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99330e790>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993324a90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993324a90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993326450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993326450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993327d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993327d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993338d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993338d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99333a990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99333a990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993350310>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993350310>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993351e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993351e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993353dd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993353dd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99336d750>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99336d750>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99336e510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99336e510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993384190>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993384190>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993385d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993385d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993387510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993387510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993394fd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993394fd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993396910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993396910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933b0050>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933b0050>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933b2390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933b2390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933b3dd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933b3dd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933c17d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933c17d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933c27d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933c27d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933e0450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933e0450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933e1d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933e1d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933e3e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933e3e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933f58d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933f58d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9972c8d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9972c8d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9937fb0d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9937fb0d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99330d1d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99330d1d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99330e790>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99330e790>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993324a90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993324a90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993326450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993326450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993327d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993327d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993338d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993338d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99333a990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99333a990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993350310>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993350310>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993351e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993351e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993353dd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993353dd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99336d750>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99336d750>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99336e510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f99336e510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993384190>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993384190>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993385d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993385d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993387510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993387510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993394fd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993394fd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993396910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f993396910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933b0050>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933b0050>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933b2390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933b2390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933b3dd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933b3dd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933c17d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933c17d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933c27d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933c27d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933e0450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933e0450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933e1d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933e1d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933e3e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933e3e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933f58d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73f9933f58d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7fa10d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7fa10d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df17e10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df17e10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df28e90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df28e90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df2a7d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df2a7d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df40450>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df40450>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df41d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df41d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df43dd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df43dd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df55790>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df55790>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df56990>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df56990>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df6cb90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df6cb90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df6e5d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df6e5d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df6ff50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df6ff50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df88d50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df88d50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df8a990>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df8a990>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfa0d90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfa0d90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfa2710>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfa2710>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfa3f10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfa3f10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfb1290>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfb1290>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfb2850>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfb2850>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfccc50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfccc50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfcde10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfcde10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfcfdd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfcfdd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfdd490>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfdd490>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfdf410>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfdf410>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dffc710>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dffc710>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dffde10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dffde10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfffa50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfffa50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7db11110>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7db11110>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7fa10d10>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df17e10>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df28e90>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df2a7d0>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df40450>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df41d10>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df43dd0>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df55790>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df56990>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df6cb90>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df6e5d0>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df6ff50>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df88d50>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df8a990>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfa0d90>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfa2710>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfa3f10>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfb1290>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfb2850>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfccc50>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfcde10>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfcfdd0>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfdd490>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfdf410>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dffc710>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dffde10>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfffa50>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7db11110>', 'Tensor(shape=torch.Size([173, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([173, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7fa10d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7fa10d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df17e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df17e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df28e90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df28e90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df2a7d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df2a7d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df40450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df40450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df41d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df41d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df43dd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df43dd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df55790>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df55790>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df56990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df56990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df6cb90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df6cb90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df6e5d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df6e5d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df6ff50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df6ff50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df88d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df88d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df8a990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df8a990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfa0d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfa0d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfa2710>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfa2710>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfa3f10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfa3f10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfb1290>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfb1290>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfb2850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfb2850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfccc50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfccc50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfcde10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfcde10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfcfdd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfcfdd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfdd490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfdd490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfdf410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfdf410>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dffc710>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dffc710>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dffde10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dffde10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfffa50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfffa50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7db11110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7db11110>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7fa10d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7fa10d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df17e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df17e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df28e90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df28e90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df2a7d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df2a7d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df40450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df40450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df41d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df41d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df43dd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df43dd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df55790>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df55790>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df56990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df56990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df6cb90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df6cb90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df6e5d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df6e5d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df6ff50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df6ff50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df88d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df88d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df8a990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7df8a990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfa0d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfa0d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfa2710>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfa2710>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfa3f10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfa3f10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfb1290>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfb1290>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfb2850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfb2850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfccc50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfccc50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfcde10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfcde10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfcfdd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfcfdd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfdd490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfdd490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfdf410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfdf410>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dffc710>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dffc710>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dffde10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dffde10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfffa50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7dfffa50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7db11110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7b4e7db11110>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d17400cc750>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d17400cc750>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d0b010>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d0b010>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d20790>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d20790>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d21e50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d21e50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d23d90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d23d90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d3d250>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d3d250>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d3ec10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d3ec10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d4cc50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d4cc50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d4ec50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d4ec50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d17278111d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d17278111d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d65fd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d65fd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d679d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d679d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d80810>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d80810>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d82d50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d82d50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d9c7d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d9c7d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d9e1d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d9e1d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d9f4d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d9f4d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723da9610>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723da9610>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723daafd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723daafd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dc41d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dc41d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dc6450>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dc6450>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dc7e50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dc7e50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dd5890>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dd5890>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dd6a10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dd6a10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723df42d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723df42d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723df5c10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723df5c10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723df7d50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723df7d50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723908b90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723908b90>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d17400cc750>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d0b010>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d20790>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d21e50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d23d90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d3d250>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d3ec10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d4cc50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d4ec50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d17278111d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d65fd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d679d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d80810>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d82d50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d9c7d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d9e1d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d9f4d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723da9610>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723daafd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dc41d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dc6450>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dc7e50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dd5890>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dd6a10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723df42d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723df5c10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723df7d50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723908b90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d17400cc750>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d17400cc750>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d0b010>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d0b010>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d20790>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d20790>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d21e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d21e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d23d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d23d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d3d250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d3d250>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d3ec10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d3ec10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d4cc50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d4cc50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d4ec50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d4ec50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d17278111d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d17278111d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d65fd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d65fd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d679d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d679d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d80810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d80810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d82d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d82d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d9c7d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d9c7d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d9e1d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d9e1d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d9f4d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d9f4d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723da9610>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723da9610>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723daafd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723daafd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dc41d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dc41d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dc6450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dc6450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dc7e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dc7e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dd5890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dd5890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dd6a10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dd6a10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723df42d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723df42d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723df5c10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723df5c10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723df7d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723df7d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723908b90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723908b90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d17400cc750>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d17400cc750>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d0b010>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d0b010>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d20790>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d20790>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d21e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d21e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d23d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d23d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d3d250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d3d250>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d3ec10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d3ec10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d4cc50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d4cc50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d4ec50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d4ec50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d17278111d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d17278111d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d65fd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d65fd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d679d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d679d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d80810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d80810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d82d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d82d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d9c7d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d9c7d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d9e1d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d9e1d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d9f4d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723d9f4d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723da9610>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723da9610>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723daafd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723daafd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dc41d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dc41d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dc6450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dc6450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dc7e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dc7e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dd5890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dd5890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dd6a10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723dd6a10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723df42d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723df42d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723df5c10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723df5c10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723df7d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723df7d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723908b90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7d1723908b90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe85615ea50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe85615ea50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82750e110>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82750e110>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827524210>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827524210>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827525750>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827525750>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827527310>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827527310>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827538e50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827538e50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82753ae50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82753ae50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827554110>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827554110>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827555b50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827555b50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827557510>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827557510>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827568e10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827568e10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82756a390>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82756a390>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827584c50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827584c50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827586450>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827586450>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827587e10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827587e10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82759d7d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82759d7d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82759e810>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82759e810>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275ac190>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275ac190>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275adb10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275adb10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275afdd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275afdd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275c4e50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275c4e50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275c67d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275c67d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275dc2d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275dc2d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275ddc50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275ddc50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275dfd50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275dfd50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275f5490>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275f5490>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275f7110>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275f7110>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827110410>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827110410>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe85615ea50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82750e110>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827524210>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827525750>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827527310>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827538e50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82753ae50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827554110>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827555b50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827557510>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827568e10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82756a390>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827584c50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827586450>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827587e10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82759d7d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82759e810>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275ac190>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275adb10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275afdd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275c4e50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275c67d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275dc2d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275ddc50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275dfd50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275f5490>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275f7110>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827110410>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe85615ea50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe85615ea50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82750e110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82750e110>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827524210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827524210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827525750>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827525750>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827527310>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827527310>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827538e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827538e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82753ae50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82753ae50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827554110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827554110>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827555b50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827555b50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827557510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827557510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827568e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827568e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82756a390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82756a390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827584c50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827584c50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827586450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827586450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827587e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827587e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82759d7d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82759d7d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82759e810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82759e810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275ac190>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275ac190>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275adb10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275adb10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275afdd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275afdd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275c4e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275c4e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275c67d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275c67d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275dc2d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275dc2d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275ddc50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275ddc50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275dfd50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275dfd50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275f5490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275f5490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275f7110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275f7110>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827110410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827110410>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe85615ea50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe85615ea50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82750e110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82750e110>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827524210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827524210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827525750>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827525750>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827527310>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827527310>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827538e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827538e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82753ae50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82753ae50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827554110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827554110>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827555b50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827555b50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827557510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827557510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827568e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827568e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82756a390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82756a390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827584c50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827584c50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827586450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827586450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827587e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827587e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82759d7d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82759d7d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82759e810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe82759e810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275ac190>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275ac190>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275adb10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275adb10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275afdd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275afdd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275c4e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275c4e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275c67d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275c67d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275dc2d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275dc2d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275ddc50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275ddc50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275dfd50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275dfd50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275f5490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275f5490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275f7110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe8275f7110>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827110410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7fe827110410>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888de828d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888de828d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcefea90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcefea90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd14550>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd14550>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd15e10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd15e10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd17f50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd17f50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd2d290>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd2d290>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd2ead0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd2ead0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd44c50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd44c50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd46610>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd46610>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd47f50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd47f50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd59390>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd59390>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd5b310>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd5b310>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd78150>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd78150>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd79d90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd79d90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd7bed0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd7bed0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd91a50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd91a50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd92850>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd92850>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda0e10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda0e10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda1bd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda1bd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda3c50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda3c50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdb9390>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdb9390>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdbab90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdbab90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcc910>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcc910>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcdc10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcdc10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcf5d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcf5d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcde9390>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcde9390>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdeab90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdeab90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dc900e90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dc900e90>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888de828d10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcefea90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd14550>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd15e10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd17f50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd2d290>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd2ead0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd44c50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd46610>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd47f50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd59390>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd5b310>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd78150>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd79d90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd7bed0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd91a50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd92850>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda0e10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda1bd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda3c50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdb9390>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdbab90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcc910>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcdc10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcf5d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcde9390>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdeab90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dc900e90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888de828d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888de828d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcefea90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcefea90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd14550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd14550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd15e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd15e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd17f50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd17f50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd2d290>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd2d290>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd2ead0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd2ead0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd44c50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd44c50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd46610>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd46610>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd47f50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd47f50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd59390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd59390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd5b310>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd5b310>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd78150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd78150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd79d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd79d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd7bed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd7bed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd91a50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd91a50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd92850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd92850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda0e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda0e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda1bd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda1bd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda3c50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda3c50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdb9390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdb9390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdbab90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdbab90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcc910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcc910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcdc10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcdc10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcf5d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcf5d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcde9390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcde9390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdeab90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdeab90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dc900e90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dc900e90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888de828d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888de828d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcefea90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcefea90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd14550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd14550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd15e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd15e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd17f50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd17f50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd2d290>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd2d290>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd2ead0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd2ead0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd44c50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd44c50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd46610>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd46610>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd47f50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd47f50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd59390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd59390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd5b310>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd5b310>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd78150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd78150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd79d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd79d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd7bed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd7bed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd91a50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd91a50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd92850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd92850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda0e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda0e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda1bd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda1bd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda3c50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda3c50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdb9390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdb9390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdbab90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdbab90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcc910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcc910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcdc10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcdc10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcf5d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcf5d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcde9390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcde9390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdeab90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdeab90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dc900e90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dc900e90>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888de828d10>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcefea90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd14550>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd15e10>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd17f50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd2d290>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd2ead0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd44c50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd46610>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd47f50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd59390>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd5b310>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd78150>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd79d90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd7bed0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd91a50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd92850>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda0e10>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda1bd0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda3c50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdb9390>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdbab90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcc910>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcdc10>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcf5d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcde9390>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdeab90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dc900e90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888de828d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888de828d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcefea90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcefea90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd14550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd14550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd15e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd15e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd17f50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd17f50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd2d290>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd2d290>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd2ead0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd2ead0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd44c50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd44c50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd46610>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd46610>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd47f50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd47f50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd59390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd59390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd5b310>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd5b310>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd78150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd78150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd79d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd79d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd7bed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd7bed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd91a50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd91a50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd92850>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcd92850>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda0e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda0e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda1bd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda1bd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda3c50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcda3c50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdb9390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdb9390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdbab90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdbab90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcc910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcc910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcdc10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcdc10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcf5d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdcf5d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcde9390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcde9390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdeab90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dcdeab90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dc900e90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7888dc900e90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c9d2c10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c9d2c10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c509d90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c509d90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c50ba50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c50ba50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c551390>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c551390>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c553090>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c553090>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5f24d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5f24d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c580b90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c580b90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c582710>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c582710>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c583f10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c583f10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5f97d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5f97d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5faed0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5faed0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5bcc50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5bcc50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5be510>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5be510>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5bf910>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5bf910>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5a1810>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5a1810>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5a3050>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5a3050>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c578950>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c578950>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c57a290>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c57a290>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c57bd90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c57bd90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c561510>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c561510>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c562e10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c562e10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c535210>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c535210>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5360d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5360d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c537890>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c537890>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5fd890>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5fd890>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5feb90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5feb90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c410490>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c410490>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c411f50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c411f50>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c9d2c10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c509d90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c50ba50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c551390>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c553090>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5f24d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c580b90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c582710>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c583f10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5f97d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5faed0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5bcc50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5be510>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5bf910>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5a1810>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5a3050>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c578950>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c57a290>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c57bd90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c561510>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c562e10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c535210>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5360d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c537890>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5fd890>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5feb90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c410490>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c411f50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c9d2c10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c9d2c10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c509d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c509d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c50ba50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c50ba50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c551390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c551390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c553090>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c553090>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5f24d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5f24d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c580b90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c580b90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c582710>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c582710>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c583f10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c583f10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5f97d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5f97d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5faed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5faed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5bcc50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5bcc50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5be510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5be510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5bf910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5bf910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5a1810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5a1810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5a3050>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5a3050>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c578950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c578950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c57a290>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c57a290>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c57bd90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c57bd90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c561510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c561510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c562e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c562e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c535210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c535210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5360d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5360d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c537890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c537890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5fd890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5fd890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5feb90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5feb90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c410490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c410490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c411f50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c411f50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c9d2c10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c9d2c10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c509d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c509d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c50ba50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c50ba50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c551390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c551390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c553090>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c553090>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5f24d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5f24d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c580b90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c580b90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c582710>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c582710>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c583f10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c583f10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5f97d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5f97d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5faed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5faed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5bcc50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5bcc50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5be510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5be510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5bf910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5bf910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5a1810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5a1810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5a3050>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5a3050>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c578950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c578950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c57a290>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c57a290>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c57bd90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c57bd90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c561510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c561510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c562e10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c562e10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c535210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c535210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5360d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5360d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c537890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c537890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5fd890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5fd890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5feb90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c5feb90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c410490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c410490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c411f50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x75c04c411f50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73721c3fd0d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73721c3fd0d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d168d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d168d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2cd50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2cd50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2df50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2df50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2fdd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2fdd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d45a90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d45a90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d46890>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d46890>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d582d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d582d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5a810>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5a810>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5bfd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5bfd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d71150>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d71150>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d72b50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d72b50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d90ed0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d90ed0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d92090>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d92090>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d93cd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d93cd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7da9610>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7da9610>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7daadd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7daadd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db8810>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db8810>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db9f10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db9f10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dbbed0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dbbed0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd1390>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd1390>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd34d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd34d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de8ed0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de8ed0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de9ed0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de9ed0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7debe90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7debe90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7901150>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7901150>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7902890>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7902890>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7918250>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7918250>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73721c3fd0d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d168d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2cd50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2df50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2fdd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d45a90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d46890>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d582d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5a810>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5bfd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d71150>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d72b50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d90ed0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d92090>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d93cd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7da9610>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7daadd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db8810>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db9f10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dbbed0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd1390>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd34d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de8ed0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de9ed0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7debe90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7901150>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7902890>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7918250>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73721c3fd0d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73721c3fd0d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d168d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d168d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2cd50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2cd50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2df50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2df50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2fdd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2fdd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d45a90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d45a90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d46890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d46890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d582d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d582d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5a810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5a810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5bfd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5bfd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d71150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d71150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d72b50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d72b50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d90ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d90ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d92090>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d92090>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d93cd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d93cd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7da9610>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7da9610>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7daadd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7daadd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db8810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db8810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db9f10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db9f10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dbbed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dbbed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd1390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd1390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd34d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd34d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de8ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de8ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de9ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de9ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7debe90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7debe90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7901150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7901150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7902890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7902890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7918250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7918250>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73721c3fd0d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73721c3fd0d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d168d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d168d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2cd50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2cd50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2df50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2df50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2fdd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2fdd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d45a90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d45a90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d46890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d46890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d582d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d582d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5a810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5a810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5bfd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5bfd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d71150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d71150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d72b50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d72b50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d90ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d90ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d92090>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d92090>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d93cd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d93cd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7da9610>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7da9610>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7daadd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7daadd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db8810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db8810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db9f10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db9f10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dbbed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dbbed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd1390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd1390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd34d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd34d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de8ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de8ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de9ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de9ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7debe90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7debe90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7901150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7901150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7902890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7902890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7918250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7918250>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73721c3fd0d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d168d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2cd50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2df50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2fdd0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d45a90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d46890>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d582d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5a810>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5bfd0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d71150>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d72b50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d90ed0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d92090>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d93cd0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7da9610>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7daadd0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db8810>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db9f10>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dbbed0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd1390>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd34d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de8ed0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de9ed0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7debe90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7901150>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7902890>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7918250>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73721c3fd0d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73721c3fd0d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d168d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d168d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2cd50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2cd50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2df50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2df50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2fdd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2fdd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d45a90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d45a90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d46890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d46890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d582d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d582d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5a810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5a810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5bfd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5bfd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d71150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d71150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d72b50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d72b50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d90ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d90ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d92090>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d92090>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d93cd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d93cd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7da9610>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7da9610>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7daadd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7daadd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db8810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db8810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db9f10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db9f10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dbbed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dbbed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd1390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd1390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd34d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd34d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de8ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de8ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de9ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de9ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7debe90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7debe90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7901150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7901150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7902890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7902890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7918250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7918250>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73721c3fd0d0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d168d0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2cd50>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2df50>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2fdd0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d45a90>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d46890>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d582d0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5a810>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5bfd0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d71150>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d72b50>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d90ed0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d92090>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d93cd0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7da9610>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7daadd0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db8810>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db9f10>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dbbed0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd1390>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd34d0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de8ed0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de9ed0>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7debe90>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7901150>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7902890>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7918250>', 'Tensor(shape=torch.Size([22, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([22, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73721c3fd0d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x73721c3fd0d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d168d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d168d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2cd50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2cd50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2df50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2df50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2fdd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d2fdd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d45a90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d45a90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d46890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d46890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d582d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d582d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5a810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5a810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5bfd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d5bfd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d71150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d71150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d72b50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d72b50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d90ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d90ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d92090>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d92090>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d93cd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7d93cd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7da9610>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7da9610>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7daadd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7daadd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db8810>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db8810>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db9f10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7db9f10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dbbed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dbbed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd1390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd1390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd34d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7dd34d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de8ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de8ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de9ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7de9ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7debe90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7debe90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7901150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7901150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7902890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7902890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7918250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7371f7918250>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a1b4ac10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a1b4ac10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a000e710>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a000e710>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0028ad0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0028ad0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0029d50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0029d50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a002bd50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a002bd50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a003d750>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a003d750>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a003e510>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a003e510>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00582d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00582d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0059d50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0059d50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a005bd50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a005bd50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a006d0d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a006d0d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a006e450>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a006e450>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0088090>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0088090>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0089bd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0089bd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a008bd50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a008bd50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00a1190>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00a1190>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00a2510>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00a2510>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b0110>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b0110>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b2550>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b2550>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b3f10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b3f10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00c9150>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00c9150>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00ca890>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00ca890>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e40d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e40d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e5bd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e5bd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e7f50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e7f50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00f9910>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00f9910>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00fab90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00fab90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef58ff102d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef58ff102d0>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a1b4ac10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a000e710>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0028ad0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0029d50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a002bd50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a003d750>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a003e510>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00582d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0059d50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a005bd50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a006d0d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a006e450>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0088090>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0089bd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a008bd50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00a1190>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00a2510>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b0110>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b2550>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b3f10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00c9150>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00ca890>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e40d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e5bd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e7f50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00f9910>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00fab90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef58ff102d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a1b4ac10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a1b4ac10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a000e710>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a000e710>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0028ad0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0028ad0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0029d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0029d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a002bd50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a002bd50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a003d750>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a003d750>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a003e510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a003e510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00582d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00582d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0059d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0059d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a005bd50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a005bd50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a006d0d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a006d0d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a006e450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a006e450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0088090>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0088090>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0089bd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0089bd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a008bd50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a008bd50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00a1190>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00a1190>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00a2510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00a2510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b0110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b0110>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b2550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b2550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b3f10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b3f10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00c9150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00c9150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00ca890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00ca890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e40d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e40d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e5bd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e5bd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e7f50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e7f50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00f9910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00f9910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00fab90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00fab90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef58ff102d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef58ff102d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a1b4ac10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a1b4ac10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a000e710>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a000e710>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0028ad0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0028ad0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0029d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0029d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a002bd50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a002bd50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a003d750>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a003d750>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a003e510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a003e510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00582d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00582d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0059d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0059d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a005bd50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a005bd50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a006d0d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a006d0d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a006e450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a006e450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0088090>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0088090>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0089bd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0089bd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a008bd50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a008bd50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00a1190>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00a1190>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00a2510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00a2510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b0110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b0110>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b2550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b2550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b3f10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b3f10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00c9150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00c9150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00ca890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00ca890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e40d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e40d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e5bd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e5bd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e7f50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e7f50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00f9910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00f9910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00fab90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00fab90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef58ff102d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef58ff102d0>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a1b4ac10>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a000e710>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0028ad0>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0029d50>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a002bd50>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a003d750>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a003e510>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00582d0>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0059d50>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a005bd50>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a006d0d0>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a006e450>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0088090>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0089bd0>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a008bd50>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00a1190>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00a2510>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b0110>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b2550>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b3f10>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00c9150>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00ca890>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e40d0>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e5bd0>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e7f50>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00f9910>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00fab90>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef58ff102d0>', 'Tensor(shape=torch.Size([25, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([25, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a1b4ac10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a1b4ac10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a000e710>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a000e710>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0028ad0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0028ad0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0029d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0029d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a002bd50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a002bd50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a003d750>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a003d750>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a003e510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a003e510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00582d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00582d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0059d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0059d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a005bd50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a005bd50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a006d0d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a006d0d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a006e450>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a006e450>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0088090>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0088090>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0089bd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a0089bd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a008bd50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a008bd50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00a1190>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00a1190>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00a2510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00a2510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b0110>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b0110>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b2550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b2550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b3f10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00b3f10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00c9150>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00c9150>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00ca890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00ca890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e40d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e40d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e5bd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e5bd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e7f50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00e7f50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00f9910>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00f9910>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00fab90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef5a00fab90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef58ff102d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7ef58ff102d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0271c690>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0271c690>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00949950>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00949950>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0094b1d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0094b1d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00dfe510>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00dfe510>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0274e8d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0274e8d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098f1d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098f1d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e5e50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e5e50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e7ad0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e7ad0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00988ed0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00988ed0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098a890>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098a890>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c4690>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c4690>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c5fd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c5fd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c74d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c74d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b0fd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b0fd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b2dd0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b2dd0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00998710>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00998710>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099a090>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099a090>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099ba90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099ba90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00971210>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00971210>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00972d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00972d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00958410>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00958410>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095a690>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095a690>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095b950>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095b950>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00930f90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00930f90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00932a90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00932a90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fc2d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fc2d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fdb50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fdb50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009ff410>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009ff410>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0271c690>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00949950>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0094b1d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00dfe510>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0274e8d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098f1d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e5e50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e7ad0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00988ed0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098a890>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c4690>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c5fd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c74d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b0fd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b2dd0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00998710>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099a090>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099ba90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00971210>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00972d10>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00958410>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095a690>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095b950>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00930f90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00932a90>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fc2d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fdb50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009ff410>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0271c690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0271c690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00949950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00949950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0094b1d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0094b1d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00dfe510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00dfe510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0274e8d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0274e8d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098f1d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098f1d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e5e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e5e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e7ad0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e7ad0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00988ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00988ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098a890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098a890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c4690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c4690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c5fd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c5fd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c74d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c74d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b0fd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b0fd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b2dd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b2dd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00998710>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00998710>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099a090>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099a090>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099ba90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099ba90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00971210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00971210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00972d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00972d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00958410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00958410>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095a690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095a690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095b950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095b950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00930f90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00930f90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00932a90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00932a90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fc2d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fc2d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fdb50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fdb50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009ff410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009ff410>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0271c690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0271c690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00949950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00949950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0094b1d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0094b1d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00dfe510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00dfe510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0274e8d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0274e8d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098f1d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098f1d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e5e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e5e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e7ad0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e7ad0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00988ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00988ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098a890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098a890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c4690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c4690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c5fd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c5fd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c74d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c74d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b0fd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b0fd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b2dd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b2dd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00998710>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00998710>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099a090>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099a090>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099ba90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099ba90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00971210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00971210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00972d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00972d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00958410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00958410>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095a690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095a690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095b950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095b950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00930f90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00930f90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00932a90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00932a90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fc2d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fc2d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fdb50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fdb50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009ff410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009ff410>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0271c690>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00949950>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0094b1d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00dfe510>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0274e8d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098f1d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e5e50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e7ad0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00988ed0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098a890>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c4690>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c5fd0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c74d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b0fd0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b2dd0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00998710>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099a090>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099ba90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00971210>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00972d10>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00958410>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095a690>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095b950>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00930f90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00932a90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fc2d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fdb50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009ff410>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0271c690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0271c690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00949950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00949950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0094b1d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0094b1d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00dfe510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00dfe510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0274e8d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0274e8d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098f1d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098f1d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e5e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e5e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e7ad0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e7ad0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00988ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00988ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098a890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098a890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c4690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c4690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c5fd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c5fd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c74d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c74d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b0fd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b0fd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b2dd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b2dd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00998710>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00998710>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099a090>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099a090>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099ba90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099ba90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00971210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00971210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00972d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00972d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00958410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00958410>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095a690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095a690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095b950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095b950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00930f90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00930f90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00932a90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00932a90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fc2d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fc2d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fdb50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fdb50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009ff410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009ff410>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0271c690>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00949950>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0094b1d0>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00dfe510>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0274e8d0>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098f1d0>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e5e50>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e7ad0>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00988ed0>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098a890>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c4690>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c5fd0>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c74d0>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b0fd0>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b2dd0>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00998710>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099a090>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099ba90>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00971210>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00972d10>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00958410>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095a690>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095b950>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00930f90>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00932a90>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fc2d0>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fdb50>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009ff410>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0271c690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0271c690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00949950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00949950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0094b1d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0094b1d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00dfe510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00dfe510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0274e8d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0274e8d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098f1d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098f1d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e5e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e5e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e7ad0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e7ad0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00988ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00988ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098a890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098a890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c4690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c4690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c5fd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c5fd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c74d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c74d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b0fd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b0fd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b2dd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b2dd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00998710>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00998710>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099a090>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099a090>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099ba90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099ba90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00971210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00971210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00972d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00972d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00958410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00958410>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095a690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095a690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095b950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095b950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00930f90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00930f90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00932a90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00932a90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fc2d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fc2d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fdb50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fdb50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009ff410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009ff410>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0271c690>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00949950>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0094b1d0>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00dfe510>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0274e8d0>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098f1d0>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e5e50>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e7ad0>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00988ed0>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098a890>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c4690>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c5fd0>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c74d0>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b0fd0>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b2dd0>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00998710>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099a090>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099ba90>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00971210>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00972d10>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00958410>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095a690>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095b950>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00930f90>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00932a90>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fc2d0>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fdb50>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009ff410>', 'Tensor(shape=torch.Size([24, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([24, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0271c690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0271c690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00949950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00949950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0094b1d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0094b1d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00dfe510>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00dfe510>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0274e8d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0274e8d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098f1d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098f1d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e5e50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e5e50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e7ad0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e7ad0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00988ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00988ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098a890>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098a890>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c4690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c4690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c5fd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c5fd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c74d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c74d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b0fd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b0fd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b2dd0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009b2dd0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00998710>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00998710>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099a090>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099a090>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099ba90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0099ba90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00971210>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00971210>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00972d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00972d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00958410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00958410>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095a690>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095a690>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095b950>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0095b950>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00930f90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00930f90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00932a90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00932a90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fc2d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fc2d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fdb50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009fdb50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009ff410>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009ff410>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0271c690>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00949950>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0094b1d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00dfe510>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0274e8d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098f1d0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e5e50>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009e7ad0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f00988ed0>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f0098a890>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x734f009c4690>', 'Tensor(shape=torch.Size([20, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([20, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b2cf6990>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b2cf6990>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d07d90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d07d90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d1d190>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d1d190>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d1e6d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d1e6d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d34a90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d34a90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d36490>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d36490>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d37d90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d37d90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d489d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d489d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d4a9d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d4a9d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d60b50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d60b50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d62550>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d62550>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d63990>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d63990>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d7d1d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d7d1d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d7e6d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d7e6d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d945d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d945d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d95d50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d95d50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d97d50>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d97d50>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0da5ad0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0da5ad0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0da6f10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0da6f10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc02d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc02d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc1f10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc1f10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc3ed0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc3ed0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dd1390>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dd1390>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dd2d10>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dd2d10>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df0250>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df0250>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df27d0>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df27d0>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df3e90>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df3e90>']
Kwargs: {}

KTransformersExperts.load
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)']
Kwargs: {}

KExpertsCPU.load
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0c09390>', 'None']
Kwargs: {'warmup': 'True'}

KExpertsCPU.load_weights
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0c09390>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b2cf6990>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d07d90>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d1d190>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d1e6d0>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d34a90>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d36490>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d37d90>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d489d0>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d4a9d0>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d60b50>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d62550>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d63990>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d7d1d0>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d7e6d0>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d945d0>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d95d50>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d97d50>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0da5ad0>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0da6f10>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc02d0>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc1f10>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc3ed0>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dd1390>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dd2d10>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df0250>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df27d0>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df3e90>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0c09390>', 'Tensor(shape=torch.Size([33, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([33, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b2cf6990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b2cf6990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d07d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d07d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d1d190>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d1d190>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d1e6d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d1e6d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d34a90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d34a90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d36490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d36490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d37d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d37d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d489d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d489d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d4a9d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d4a9d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d60b50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d60b50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d62550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d62550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d63990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d63990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d7d1d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d7d1d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d7e6d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d7e6d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d945d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d945d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d95d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d95d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d97d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d97d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0da5ad0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0da5ad0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0da6f10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0da6f10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc02d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc02d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc1f10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc1f10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc3ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc3ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dd1390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dd1390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dd2d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dd2d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df0250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df0250>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df27d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df27d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df3e90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df3e90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0c09390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0c09390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b2cf6990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b2cf6990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d07d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d07d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d1d190>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d1d190>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d1e6d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d1e6d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d34a90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d34a90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d36490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d36490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d37d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d37d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d489d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d489d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d4a9d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d4a9d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d60b50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d60b50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d62550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d62550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d63990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d63990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d7d1d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d7d1d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d7e6d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d7e6d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d945d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d945d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d95d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d95d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d97d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d97d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0da5ad0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0da5ad0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0da6f10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0da6f10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc02d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc02d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc1f10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc1f10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc3ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc3ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dd1390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dd1390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dd2d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dd2d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df0250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df0250>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df27d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df27d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df3e90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df3e90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0c09390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0c09390>']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b2cf6990>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d07d90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d1d190>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d1e6d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d34a90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d36490>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d37d90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d489d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d4a9d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d60b50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d62550>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d63990>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d7d1d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d7e6d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d945d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d95d50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d97d50>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0da5ad0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0da6f10>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc02d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc1f10>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc3ed0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dd1390>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dd2d10>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df0250>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df27d0>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df3e90>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KTransformersExperts.forward
Args: ['KTransformersExperts(\n  (orig_module): ModuleList(\n    (0-63): 64 x Qwen2MoeMLP(\n      (gate_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (up_proj): Linear(in_features=3584, out_features=2560, bias=False)\n      (down_proj): Linear(in_features=2560, out_features=3584, bias=False)\n      (act_fn): SiLU()\n    )\n  )\n)', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.forward
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0c09390>', 'Tensor(shape=torch.Size([21, 3584]), dtype=torch.bfloat16, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.int64, device=cpu)', 'Tensor(shape=torch.Size([21, 8]), dtype=torch.bfloat16, device=cpu)']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b2cf6990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b2cf6990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d07d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d07d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d1d190>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d1d190>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d1e6d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d1e6d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d34a90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d34a90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d36490>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d36490>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d37d90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d37d90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d489d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d489d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d4a9d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d4a9d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d60b50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d60b50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d62550>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d62550>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d63990>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d63990>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d7d1d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d7d1d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d7e6d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d7e6d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d945d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d945d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d95d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d95d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d97d50>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0d97d50>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0da5ad0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0da5ad0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0da6f10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0da6f10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc02d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc02d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc1f10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc1f10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc3ed0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dc3ed0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dd1390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dd1390>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dd2d10>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0dd2d10>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df0250>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df0250>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df27d0>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df27d0>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df3e90>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0df3e90>']
Kwargs: {}

KExpertsCPU.submit_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0c09390>', 'Tensor(shape=torch.Size([3584]), dtype=torch.bfloat16, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.int64, device=cuda:0)', 'Tensor(shape=torch.Size([8]), dtype=torch.bfloat16, device=cuda:0)']
Kwargs: {}

KExpertsCPU.sync_for_one_decode
Args: ['<ktransformers.operators.experts.KExpertsCPU object at 0x7517b0c09390>']
Kwargs: {}
